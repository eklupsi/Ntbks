{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.optim.adam import Adam\n",
    "from gulpio import transforms\n",
    "from gulpio.dataset import GulpVideoDataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "step_size = 1\n",
    "num_frames = 24\n",
    "num_workers = 8\n",
    "\n",
    "frame_size = (96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GulpVideoDatasetBoundingBoxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-248b4b54322f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -- Datasets (Objects: transformation, Config: data_dir, custom_options)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_data = GulpVideoDatasetBoundingBoxes(data_path='/mnt/data02/data/20bn-jester/gulp/training',\n\u001b[0m\u001b[1;32m      3\u001b[0m                                            \u001b[0mnum_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_frames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                            \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                            \u001b[0mis_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GulpVideoDatasetBoundingBoxes' is not defined"
     ]
    }
   ],
   "source": [
    "# -- Datasets (Objects: transformation, Config: data_dir, custom_options)\n",
    "train_data = GulpVideoDatasetBoundingBoxes(data_path='/mnt/data02/data/20bn-jester/gulp/training',\n",
    "                                           num_frames=num_frames,\n",
    "                                           step_size=step_size,\n",
    "                                           is_val=False,\n",
    "                                           stack=False,\n",
    "                                           transform=train_transform,\n",
    "                                           target_transform=lambda label_tuple: label_tuple[0])\n",
    "\n",
    "val_data = GulpVideoDatasetBoundingBoxes(data_path='/mnt/data02/data/20bn-jester/gulp/validation',\n",
    "                                         num_frames=num_frames,\n",
    "                                         step_size=step_size,\n",
    "                                         is_val=True,\n",
    "                                         stack=False,\n",
    "                                         transform=validation_transform,\n",
    "                                         target_transform=lambda label_tuple: label_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9edb222ad31e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -- Data loaders (Objects: dataset, Config: batch_size, num_workers, shuffle)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m train_loader = DataLoader(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# -- Data loaders (Objects: dataset, Config: batch_size, num_workers, shuffle)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-184cd85f4833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# transforms.Scale(config['frame_size']),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         Normalize(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# -- Transformations\n",
    "train_transform = transforms.ComposeVideo(\n",
    "    img_transforms=[\n",
    "        # transforms.Scale(config['frame_size']),\n",
    "        transforms.Scale((128, 128)),\n",
    "        transforms.RandomCrop(frame_size),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),  # default values for imagenet\n",
    "            std=(0.229, 0.224, 0.225)\n",
    "        )\n",
    "    ],\n",
    "    video_transforms=[\n",
    "        lambda frames: torch.stack(frames),\n",
    "        lambda frames_tensor: frames_tensor.permute(1, 0, 2, 3)  # channels first\n",
    "    ]\n",
    ")\n",
    "validation_transform = transforms.ComposeVideo(\n",
    "    img_transforms=[\n",
    "        # transforms.Scale(config['frame_size']),\n",
    "        transforms.Scale((128, 128)),\n",
    "        transforms.CenterCrop(frame_size),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),  # default values for imagenet\n",
    "            std=(0.229, 0.224, 0.225)\n",
    "        )\n",
    "    ],\n",
    "    video_transforms=[\n",
    "        lambda frames: torch.stack(frames),\n",
    "        lambda frames_tensor: frames_tensor.permute(1, 0, 2, 3)  # channels first\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSpatialMaxPooling(nn.Module):\n",
    "    \"\"\"\n",
    "    Global maxpooling operation on the last two dimensions.\n",
    "    # Input shape\n",
    "        5D tensor with shape: `(samples, channels, steps, height, width)`.\n",
    "    # Output shape\n",
    "        5D tensor with shape: `(samples, channels, steps, 1, 1)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        kernel_size = (1,) + tuple(x.size()[-2:])\n",
    "        return F.max_pool3d(x, kernel_size=kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDistributedLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out, activation):\n",
    "        super(TimeDistributedLinear, self).__init__()\n",
    "        self.linear = nn.Linear(num_in, num_out)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndimension() == 2:\n",
    "            return self.activation(self.linear(x))\n",
    "        batch_size, num_steps, num_in = x.size()\n",
    "        x = x.contiguous().view(-1, num_in)\n",
    "        x = self.activation(self.linear(x))\n",
    "        return x.view(batch_size, num_steps, x.size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    #def _create_conv(self, i, l, p):         \n",
    "    #    setattr(self, 'conv'+str(i),  nn.Conv3d(in_channels=3, out_channels, kernel_size, bias=False))\n",
    "    #    setattr(self, 'bnorm'+str(i), nn.BatchNorm3d())\n",
    "    #    if p:\n",
    "    #        setattr(self, 'pool'+str(i),  nn.MaxPool3d((1, 2, 2)))\n",
    "    #    setattr(self, 'act1'+str(i),  nn.ReLU())\n",
    "\n",
    "    #def _conv_forward(self, i, x):\n",
    "    #    h = self.\n",
    "        \n",
    "        \n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        \n",
    "        self.use_cuda = False\n",
    "        self.gpus = [0]\n",
    "        #self.initialization_scheme = initialization_scheme\n",
    "        \n",
    "        num_features = 256\n",
    "        num_classes = 30\n",
    "        \n",
    "        kernel_base = 32\n",
    "        layers = [kernel_base, 2*kernel_base, 4*kernel_base, 8*kernel_base, 8*kernel_base, 8*kernel_base]\n",
    "        self._pool = [True, True, True, False, False, False]\n",
    "        \n",
    "        # L1\n",
    "        self.conv1  = nn.Conv3d(in_channels=3, out_channels=layers[0], kernel_size=(3,3,3), bias=False)\n",
    "        self.bnorm1 = nn.BatchNorm3d(layers[0])\n",
    "        self.pool1  = nn.MaxPool3d((1, 2, 2))\n",
    "        self.act1   = nn.ReLU()\n",
    "        \n",
    "        # L2\n",
    "        self.conv2  = nn.Conv3d(in_channels=layers[0], out_channels=layers[1], kernel_size=(3,3,3), bias=False)\n",
    "        self.bnorm2 = nn.BatchNorm3d(layers[1])\n",
    "        self.pool2  = nn.MaxPool3d((1, 2, 2))\n",
    "        self.act2   = nn.ReLU()\n",
    "        \n",
    "        # L3\n",
    "        self.conv3  = nn.Conv3d(in_channels=layers[1], out_channels=layers[2], kernel_size=(3,3,3), bias=False)\n",
    "        self.bnorm3 = nn.BatchNorm3d(layers[2])\n",
    "        self.pool3  = nn.MaxPool3d((1, 2, 2))\n",
    "        self.act3   = nn.ReLU()\n",
    "        \n",
    "        # L4\n",
    "        self.conv4  = nn.Conv3d(in_channels=layers[2], out_channels=layers[3], kernel_size=(3,3,3), bias=False)\n",
    "        self.bnorm4 = nn.BatchNorm3d(layers[3])\n",
    "        self.act4   = nn.ReLU()\n",
    "        \n",
    "        # L5\n",
    "        self.conv5  = nn.Conv3d(in_channels=layers[3], out_channels=layers[4], kernel_size=(3,3,3), bias=False)\n",
    "        self.bnorm5 = nn.BatchNorm3d(layers[4])\n",
    "        self.act5   = nn.ReLU()\n",
    "        \n",
    "        # L6\n",
    "        self.conv6  = nn.Conv3d(in_channels=layers[4], out_channels=layers[5], kernel_size=(3,3,3), bias=False)\n",
    "        self.bnorm6 = nn.BatchNorm3d(layers[5])\n",
    "        self.pool6 = GlobalSpatialMaxPooling()\n",
    "        self.act6   = nn.ReLU()\n",
    "        \n",
    "        # L7\n",
    "        self.lstm = nn.LSTM(8 * kernel_base, num_features, 2, batch_first=True,\n",
    "                    bidirectional=False)\n",
    "        \n",
    "        self.logsoftmax = TimeDistributedLinear(num_features, num_classes,\n",
    "                                                nn.LogSoftmax())\n",
    "        \n",
    "    def extract_features(self, x):\n",
    "        # L1\n",
    "        h = self.conv1(x)\n",
    "        h = self.bnorm1(h)\n",
    "        h = self.pool1(h)\n",
    "        h = self.act1(h)\n",
    "    \n",
    "        # L2\n",
    "        h = self.conv2(x)\n",
    "        h = self.bnorm2(h)\n",
    "        h = self.pool2(h)\n",
    "        h = self.act2(h)\n",
    "    \n",
    "        # L3\n",
    "        h = self.conv3(x)\n",
    "        h = self.bnorm3(h)\n",
    "        h = self.pool3(h)\n",
    "        h = self.act3(h)\n",
    "    \n",
    "        # L4\n",
    "        h = self.conv4(x)\n",
    "        h = self.bnorm4(h)\n",
    "        h = self.act4(h)\n",
    "    \n",
    "        # L5\n",
    "        h = self.conv5(x)\n",
    "        h = self.bnorm5(h)\n",
    "        h = self.act5(h)\n",
    "    \n",
    "        # L6\n",
    "        h = self.conv6(x)\n",
    "        h = self.bnorm6(h)\n",
    "        h = self.pool6(h)\n",
    "        h = self.act6(h)\n",
    "        \n",
    "        h = h.view(h.size()[0:3])\n",
    "        h = h.permute(0, 2, 1)\n",
    "        \n",
    "        # Batch, Time, Channel, Col, Row\n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "        features = self.lstm(h, None)[0]\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.extract_features(x)\n",
    "        \n",
    "        probs = self.logsoftmax(features)\n",
    "        if probs.ndimension() == 3:\n",
    "            probs = probs.mean(dim=1)\n",
    "        return probs\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6e3365a197b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_dir'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'./out'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptimizer_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-3c806c6ed2c0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "model = MyNet()\n",
    "\n",
    "\n",
    "optimizer_params={'lr': 0.01, 'momentum': 0.9, 'output_dir': './out'}\n",
    "optimizer = optim.Adam(model.parameters(), **optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-24f9fd18d946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "use_cuda = False\n",
    "for epoch in range(n):\n",
    "    \n",
    "    for batch_idx, (x, target) in enumerate(data_loader):\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "            target = target.cuda()\n",
    "                    \n",
    "            # optimization step  \n",
    "            model.train(mode=True) # training mode\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # turn tensors into autograd variables                                                                              \n",
    "            x, target = Variable(x_batch), Variable(target_batch)\n",
    "            # forward pass                                                                                                      \n",
    "            output = self.model(x)\n",
    "            loss = self.criterion(output, target)\n",
    "            # backward pass                                                                                                     \n",
    "            loss.backward()\n",
    "            # update                                                                                                            \n",
    "            self.optimizer.step()\n",
    "                                                                                  \n",
    "            train_loss = loss.data[0]\n",
    "            pred_labels = get_pred_label_from_output(output, multiclass=self.multiclass).data\n",
    "            pred_labels = self._cast_pred_labels(pred_labels)\n",
    "            train_accuracy = ((pred_labels == target).sum() / target.size(0))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
